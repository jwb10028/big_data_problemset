Summer 2024 Big Data Course Assignments ======================================= This README provides an overview of the assignments completed during the Summer 2024 Big Data course. Each assignment was designed to deepen our understanding of key big data technologies, including Hadoop MapReduce, Apache Spark, and MongoDB. Assignment 1: Hadoop MapReduce ------------------------------ ### Objective The goal of this assignment was to develop a solid understanding of the Hadoop MapReduce framework. We implemented a MapReduce job to process a dataset and extract meaningful insights by designing custom mappers and reducers. ### Key Tasks * **Data Input**: Processed a large dataset using Hadoop's HDFS. * **Mapper Implementation**: Wrote a Python script for the mapper to filter and format the input data. * **Reducer Implementation**: Created a Python script for the reducer to aggregate and summarize the data. * **Execution**: Used Hadoop streaming to run the MapReduce job and analyzed the output. Assignment 2: Apache Spark -------------------------- ### Objective This assignment introduced Apache Spark as a more efficient alternative to Hadoop MapReduce for big data processing. We focused on writing Spark applications to perform data transformations and actions. ### Key Tasks * **Data Loading**: Loaded and explored a large dataset using Apache Spark. * **Transformations**: Applied various Spark transformations, such as `map`, `filter`, and `reduceByKey`, to manipulate the data. * **Actions**: Executed Spark actions like `collect` and `saveAsTextFile` to gather and store results. * **Optimization**: Implemented strategies to optimize Spark jobs, including caching and partitioning. Assignment 3: MongoDB --------------------- ### Objective The third assignment was centered around NoSQL databases, with a particular focus on MongoDB. We learned how to store, query, and manipulate large datasets using MongoDB's flexible schema model. ### Key Tasks * **Database Setup**: Installed and configured MongoDB on a local or cloud environment. * **Data Ingestion**: Imported a JSON dataset into MongoDB and explored the data structure. * **CRUD Operations**: Performed Create, Read, Update, and Delete (CRUD) operations on the MongoDB collections. * **Aggregation**: Used MongoDBâ€™s aggregation framework to perform complex queries and data analysis.


